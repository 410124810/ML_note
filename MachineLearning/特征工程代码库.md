### 基于lambda函数 + apply

```
df['dow'] = df['created'].apply(lambda x: x.date().weekday())
df['is_weekend'] = df['created'].apply(lambda x: 1 if x.date().weekday() in (5, 6) else 0)
```
### 读取数据  
```
app_categories = read_csv_file('./data/app_categories.csv',logging=True)  

user.columns  

user[user.age!=0].describe()

user.age.value_counts()

user.info()

train_data.head()

```
### 合并数据
```
#train data
train_data['clickTime_day'] = train_data['clickTime'].apply(get_time_day)
train_data['clickTime_hour']= train_data['clickTime'].apply(get_time_hour)
# train_data['conversionTime_day'] = train_data['conversionTime'].apply(get_time_day)
# train_data['conversionTime_hour'] = train_data['conversionTime'].apply(get_time_hour)


#test_data
test_data = read_csv_file('./data/test.csv', True)
test_data['clickTime_day'] = test_data['clickTime'].apply(get_time_day)
test_data['clickTime_hour']= test_data['clickTime'].apply(get_time_hour)
# test_data['conversionTime_day'] = test_data['conversionTime'].apply(get_time_day)
# test_data['conversionTime_hour'] = test_data['conversionTime'].apply(get_time_hour)


train_user = pd.merge(train_data,user,on='userID')
train_user_ad = pd.merge(train_user,ad,on='creativeID')
train_user_ad_app = pd.merge(train_user_ad,app_categories,on='appID')
```
### 文件读取,第一类编码,数据离散化, 年龄处理，切段,省份处理,城市处理,几点钟,一天切成4段
```
import  pandas as pd
import numpy as np
import scipy as sp


#文件读取
def read_csv_file(f,logging=False):
    data = pd.read_csv(f)
    if logging:
        print (data.head(5))
        print (f,"  包含以下列....")
        print (data.columns.values)
        print (data.describe())
        print (data.info())
    return  data

#第一类编码
def categories_process_first_class(cate):
    cate = str(cate)
    if len(cate)==1:
        if int(cate)==0:
            return 0
    else:
        return int(cate[0])
#年龄处理，切段
def age_process(age):
    age = int(age)
    if age==0:
        return 0
    elif age<15:
        return 1
    elif age<25:
        return 2
    elif age<40:
        return 3
    elif age<60:
        return 4
    else:
        return 5
#省份处理
def process_province(hometown):
    hometown = str(hometown)
    province = int(hometown[0:2])
    return province

#城市处理
def process_city(hometown):
    hometown = str(hometown)
    if len(hometown)>1:
        province = int(hometown[2:])
    else:
        province = 0
    return province

#几点钟
def get_time_day(t):
    t = str(t)
    t=int(t[0:2])
    return 
    

#一天切成4段
def get_time_hour(t):
    t = str(t)
    t=int(t[2:4])
    if t<6:
        return 0
    elif t<12:
        return 1
    elif t<18:
        return 2
    else:
        return 3
#评估与计算logloss
def logloss(act, pred):
    epsilon = 1e-15
    pred = sp.maximum(epsilon, pred)
    pred = sp.minimum(1-epsilon, pred)
    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))
    ll = ll * -1.0/len(act)
    return ll

user['age_process'] = user['age'].apply(age_process)
```
### 随机森林建模&&特征重要度排序
```
# %matplotlib inline
# import matplotlib.pyplot as plt
# print('Plot feature importances...')
# ax = lgb.plot_importance(gbm, max_num_features=10)
# plt.show()
# 用RF 计算特征重要度

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, train_test_split

feat_labels = np.array(['creativeID','userID','positionID',
 'connectionType','telecomsOperator','clickTime_day','clickTime_hour','age', 'gender' ,'education',
 'marriageStatus' ,'haveBaby' , 'residence' ,'age_process',
 'hometown_province', 'hometown_city','residence_province', 'residence_city',
 'adID', 'camgaignID', 'advertiserID', 'appID' ,'appPlatform' ,
 'app_categories_first_class' ,'app_categories_second_class'])

forest = RandomForestClassifier(n_estimators=100,
                                random_state=0,
                                n_jobs=-1)

forest.fit(x_user_ad_app, y_user_ad_app.reshape(y_user_ad_app.shape[0],))
importances = forest.feature_importances_

indices = np.argsort(importances)[::-1]
```
```
import matplotlib.pyplot as plt
%matplotlib inline
for f in range(x_user_ad_app.shape[1]):
    print("%2d) %-*s %f" % (f + 1, 30, 
                            feat_labels[indices[f]], 
                            importances[indices[f]]))

plt.title('Feature Importances')
plt.bar(range(x_user_ad_app.shape[1]), 
        importances[indices],
        color='lightblue', 
        align='center')

plt.xticks(range(x_user_ad_app.shape[1]), 
           feat_labels[indices], rotation=90)
plt.xlim([-1, x_user_ad_app.shape[1]])
plt.tight_layout()
#plt.savefig('./random_forest.png', dpi=300)
plt.show()
```
### 增加 test_data 的 注册日期距离公测时间的天数
```
import datetime
import numpy
# 国内公测时间 2017年8月13日
# 增加 test_data 的 注册日期距离公测时间的天数
def add_time_dif(array):
    new_array = numpy.zeros(shape=(array.shape[0],1))

    for i in np.arange(array['register_time'].shape[0]):
        the_array = array['register_time']
        sd = datetime.datetime.strptime('2014-12-08 00:00:00', '%Y-%m-%d %H:%M:%S')
        d = datetime.datetime.strptime(the_array[i], '%Y-%m-%d %H:%M:%S')
        time = (d - sd).days + 1
        new_array[i] = int(time)    
    array['time_dif'] = new_array
    #修改为int16 减少计算量
    array['time_dif'] = numpy.int16(array['time_dif'])
    return array
    # print (test_data['time_dif'])
test_data = add_time_dif(test_data)

# 增加 train_data 的 注册日期距离公测时间的天数
def my_none():
    new_array = numpy.zeros(shape=(train_data.shape[0],1))
    array = np.array(train_data['register_time']).reshape(len(train_data['register_time']),1)
    for i in np.arange(train_data['register_time'].shape[0]):

        sd = datetime.datetime.strptime('2014-12-08 00:00:00', '%Y-%m-%d %H:%M:%S')
        d = datetime.datetime.strptime(array[i,0], '%Y-%m-%d %H:%M:%S')
        time = (d - sd).days + 1
        new_array[i] = int(time)    
    train_data['time_dif'] = new_array
    # #修改为int16 减少计算量
    train_data['time_dif'] = numpy.int16(train_data['time_dif'])
my_none()
```
### 增加新的列
```
def add_columns(train_data_X,n):
#     X_columns_len = len(array_need)
    X_columns = np.array(train_data_X.columns).reshape(1,n)
    for num in range(n):
        array = np.array(train_data_X[X_columns[0,num]])                
        array1 = array
        array2 = del_data_byhand_one(array)
        array_del = del_data_singal(array2,3)
        array3 = array2-array_del
        string = X_columns[0,num]+'del'
#         print(string)
        train_data_X[string] = array3
    return train_data_X
```
### 增加列 排名百分比
```

def add_rank_percent(df,n):
    X_columns = np.array(df.columns).reshape(1,df.columns.shape[1])
    array = np.array(df[X_columns[0,num]])
    length = len(array)
    s = pd.Series(array)
    rank = s.rank()
    rank_percent = np.divide(rank,length)
    rank_percent = np.float16(rank_percent)
    return rank_percent

for i in numpy.arange(train_feat.shape[1])[1:train_feat.shape[1]]:
    X_columns = np.array(train_feat.columns).reshape(1,train_feat.shape[1])
    train_feat[X_columns[0,i]+'_rank'] = add_rank_percent(train_feat,i)
for i in numpy.arange(test_feat.shape[1])[1:]:
    X_columns = np.array(train_feat.columns).reshape(1,df.columns.shape[1])
    train_feat[X_columns[0,i]+'_rank'] = add_rank_percent(train_feat,i)
```
